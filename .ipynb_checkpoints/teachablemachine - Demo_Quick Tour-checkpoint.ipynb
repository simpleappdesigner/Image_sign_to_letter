{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5598f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teachable machine quick demo!\n",
    "# https://teachablemachine.withgoogle.com/train\n",
    "# motivation credit - https://stackoverflow.com/questions/71816488/model-is-not-giving-correct-results-even-if-accuracy-is-good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b783b",
   "metadata": {},
   "source": [
    "## Train the model, parameters\n",
    "<img src=\"Model Training_ TM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f676f",
   "metadata": {},
   "source": [
    "## download as keras\n",
    "<img src=\"TM_save as keras.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd080a6",
   "metadata": {},
   "source": [
    "## download as Tensorflow lite\n",
    "<img src=\"TM_save_As_TFlite.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ff06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libs\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cf9e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 13:59:48.472582: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#Load label and model\n",
    "#build label dictionary\n",
    "with open(\"converted_keras/labels.txt\") as fl:\n",
    "    label_lines=fl.read().splitlines()\n",
    "labels={} # \"0\" --> A, \"1\"-->\"B\"\n",
    "for each_l in label_lines:\n",
    "    labels[each_l.split()[0]]=each_l.split()[1]\n",
    "\n",
    "#load the model\n",
    "model=tf.keras.models.load_model('converted_keras/keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f571e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 13:59:53.149889: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label :  P\n"
     ]
    }
   ],
   "source": [
    "# Predict the label\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "# Replace this with the path to your image\n",
    "image = Image.open('Screen Shot 2022-04-11 at 10.31.46 AM.png').convert('RGB')# convert screen snap to RGB\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "#print(prediction)\n",
    "print(\"Predicted label : \",labels[str(np.argmax(prediction[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4cce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now with converted_tflite\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_tflite/model_unquant.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "interpreter.invoke()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccf0ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label :  P\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('Screen Shot 2022-04-11 at 10.31.46 AM.png').convert(\"RGB\")\n",
    "img = ImageOps.fit(img, size, Image.ANTIALIAS)\n",
    "input_data = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "input_data /= 255.\n",
    "input_data\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "#print(np.argmax(output_data[0]))\n",
    "print(\"Predicted label : \",labels[str(np.argmax(output_data[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc12004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 1280)              410208    \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 29)                131000    \n",
      "=================================================================\n",
      "Total params: 541,208\n",
      "Trainable params: 527,128\n",
      "Non-trainable params: 14,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
